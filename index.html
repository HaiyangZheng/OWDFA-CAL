<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="title" content="Open-World Deepfake Attribution via Confidence-Aware Asymmetric Learning - Haiyang Zheng">
  <meta name="description" content="Open-World Deepfake Attribution (OWDFA) via Confidence-Aware Asymmetric Learning (CAL) addresses confidence skew and unknown forgery types using dynamic regularization and prototype pruning.">
  <meta name="keywords" content="Deepfake Attribution, Open-World Learning, Computer Vision, AI, Deep Learning">
  <meta name="author" content="Haiyang Zheng">
  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Open-World Deepfake Attribution via Confidence-Aware Asymmetric Learning">
  <meta property="og:description" content="Identifying known and novel deepfakes in the wild using Confidence-Aware Asymmetric Learning.">
  <meta property="og:image" content="static/images/teaser.png"> 
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Open-World Deepfake Attribution via Confidence-Aware Asymmetric Learning">
  <meta name="twitter:description" content="Identifying known and novel deepfakes in the wild using Confidence-Aware Asymmetric Learning.">
  <meta name="twitter:image" content="static/images/teaser.png">

  <title>OWDFA-CAL</title>
  
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/index.js"></script>
</head>

<body>

  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

<div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        
        <a href="https://github.com/HaiyangZheng/TextGCD" class="work-item" target="_blank" rel="noopener">
          <div class="work-info">
            <h5>Textual Knowledge Matters: Cross-Modality Co-Teaching for Generalized Visual Class Discovery</h5>
            <span class="work-venue">ECCV 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>

        <a href="https://github.com/HaiyangZheng/PHE" class="work-item" target="_blank" rel="noopener">
          <div class="work-info">
            <h5>Prototypical Hash Encoding for On-the-Fly Fine-Grained Category Discovery</h5>
            <span class="work-venue">NeurIPS 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>

        <a href="https://github.com/HaiyangZheng/MGCE" class="work-item" target="_blank" rel="noopener">
          <div class="work-info">
            <h5>MGCE: Extension of CVPR 2023 DCCL</h5>
            <span class="work-venue">Extension of CVPR 2023 DCCL</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        
      </div>
    </div>
  </div>


  <main id="main-content">

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            
            <h1 class="title is-2 publication-title">Open-World Deepfake Attribution via Confidence-Aware Asymmetric Learning</h1>
            
            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://haiyangzheng.github.io/" target="_blank">Haiyang Zheng</a><sup>1</sup>,</span>
              <span class="author-block">Nan Pu<sup>1*</sup>,</span>
              <span class="author-block">Wenjing Li<sup>2*</sup>,</span>
              <span class="author-block">Teng Long<sup>1</sup>,</span>
              <span class="author-block">Nicu Sebe<sup>1</sup>,</span>
              <span class="author-block">Zhun Zhong<sup>2</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Trento, <sup>2</sup>Hefei University of Technology<br><b>AAAI 2026</b></span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding author</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2512.12667.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/HaiyangZheng/OWDFA-CAL" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/hyzheng/OWDFA40-Benchmark" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="HF"></span>
                    <span>Dataset</span>
                  </a>
                </span>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="columns is-centered">
          <div class="column is-four-fifths has-text-centered">
            <img src="static/images/teaser.png" class="interpolation-image" alt="Detective Conan Analogy" style="max-height: 400px; width: auto;"/>
            <h2 class="subtitle has-text-centered mt-4">
              <span class="dnerf">OWDFA-CAL</span> utilizes a <b>Confidence-Aware Asymmetric Learning</b> framework to act like a detective, identifying known criminals (Known Deepfakes) and uncovering mysterious new suspects (Novel Deepfakes) in the open world.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      
      <div class="columns is-centered has-text-centered mb-6">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Task & Motivation</h2>
        </div>
      </div>

      <div class="columns is-vcentered">
        <div class="column is-6">
          <div class="content">
            <h3 class="title is-4">
              <span class="icon is-medium"><i class="fas fa-search"></i></span> 
              What is OWDFA?
            </h3>
            
            <div class="box has-background-light" style="box-shadow: none; border: 1px solid #eee;">
              <p class="has-text-weight-bold is-size-5 mb-0 has-text-centered">
                Open-World Deepfake Attribution (OWDFA)
              </p>
            </div>

            <p class="has-text-justified">
              It acts like a detective. Unlike traditional Deepfake Detection which only performs binary classification (Real vs. Fake), 
              <b>OWDFA is distinct in the following aspects</b>:
            </p>
            
            <ul class="mt-2">
              <li>
                <b>Source Tracing:</b> Distinguish <i>specifically</i> which model created the forgery (e.g., FaceDancer, Diffusion, GANs).
              </li>
              <li>
                <b>The "Open World" Challenge:</b>
                Unlabeled Data contains a complex mixture of <span class="tag is-info is-light">Known</span> and <span class="tag is-light">Novel</span> types.
              </li>
              <li>
                <b>Goal:</b> Classify knowns while discovering and clustering novels.
              </li>
            </ul>
          </div>
        </div>

        <div class="column is-6 has-text-centered">
          <figure class="image is-inline-block" style="max-width: 90%; margin: 0 auto;"> 
            <img src="static/images/task_overview.png" alt="OWDFA Task Overview" style="border-radius: 8px; box-shadow: 0 4px 10px rgba(0,0,0,0.1);">
            <figcaption class="has-text-centered is-size-7 mt-3 has-text-grey">
              Figure 1. The illustration of Open-World Deepfake Attribution.
            </figcaption>
          </figure>
        </div>
      </div>

      <hr class="divider" style="margin: 3rem 0;">

      <div class="columns is-vcentered">
        <div class="column is-6">
          <div class="columns is-mobile">
             <div class="column is-12">
              <figure class="image mb-5">
                <img src="static/images/motivation_skew.png" alt="Confidence Skew" style="border: 1px solid #eee; border-radius: 8px; padding: 5px;">
                <figcaption class="has-text-centered is-size-7 mt-1">Observation 1: Confidence Skew</figcaption>
              </figure>
              <figure class="image">
                <img src="static/images/motivation_noise.png" alt="Noise Proportion" style="border: 1px solid #eee; border-radius: 8px; padding: 5px;">
                <figcaption class="has-text-centered is-size-7 mt-1">Observation 2: Noise Proportion</figcaption>
              </figure>
             </div>
          </div>
        </div>

        <div class="column is-6">
          <div class="content">
            <h3 class="title is-4">
              <span class="icon is-medium"><i class="fas fa-exclamation-triangle"></i></span> 
              Limitations of Existing Methods
            </h3>
            <p class="has-text-justified">
              Despite recent progress, <b>current approaches suffer from two critical limitations</b>:
            </p>
            
            <div class="box has-background-light" style="box-shadow: none; border: 1px solid #eee;">
              <p class="mb-2"><b>1. Confidence Skew (The Bias)</b></p>
              <p class="is-size-6 has-text-justified mb-4">
                Existing methods exhibit a severe <b>confidence gap</b>: high confidence for known forgeries but low for novel ones. This creates a "rich get richer" loop where novel classes are ignored.
              </p>

              <p class="mb-2"><b>2. Unrealistic Assumption on <i>K</i></b></p>
              <p class="is-size-6 has-text-justified mb-0">
                Most methods assume the number of novel forgery types (<i>K</i>) is known <i>a priori</i>. Our method (CAL) removes this assumption by estimating <i>K</i> dynamically.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The proliferation of synthetic facial imagery has intensified the need for robust <b>Open-World DeepFake Attribution (OWDFA)</b>, 
              which aims to attribute both known and unknown forgeries using labeled data for known types and unlabeled data containing a mixture of known and novel types. 
              However, existing methods face two critical limitations: 
              1) A <b>confidence skew</b> leading to unreliable pseudo-labels for novel forgeries; 
              2) An unrealistic assumption that the number of unknown forgery types is known <i>a priori</i>.
            </p>
            <p>
              To address these challenges, we propose a <b>Confidence-Aware Asymmetric Learning (CAL)</b> framework. 
              CAL consists of two key components: 
              <b>Confidence-Aware Consistency Regularization (CCR)</b>, which mitigates pseudo-label bias by dynamically scaling sample losses, and 
              <b>Asymmetric Confidence Reinforcement (ACR)</b>, which separately calibrates confidence for known and novel classes.
              Together, they form a mutually reinforcing loop that significantly improves performance.
            </p>
            <p>
              Moreover, we introduce a <b>Dynamic Prototype Pruning (DPP)</b> strategy to automatically estimate the number of novel forgery types in a coarse-to-fine manner, removing unrealistic prior assumptions. 
              Extensive experiments on the standard OW-DFA benchmark and a newly extended <b>OWDFA-40 benchmark</b> demonstrate that CAL consistently achieves new state-of-the-art performance.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      
      <h2 class="title is-3 has-text-centered mb-5">Method: Confidence-Aware Asymmetric Learning</h2>
      
      <figure class="image mb-5" style="margin-left: auto; margin-right: auto;">
        <img src="static/images/framework.png" alt="CAL Framework Pipeline" style="width: 100%; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.05);">
      </figure>

      <div class="box has-background-light">
        <div class="content">
          <h4 class="title is-5 has-text-centered mb-4">Core Components of CAL</h4>
          
          <div class="columns is-multiline">
            
            <div class="column is-12">
              <div class="media">
                <div class="media-left">
                  <span class="icon is-large has-text-info"><i class="fas fa-balance-scale fa-2x"></i></span>
                </div>
                <div class="media-content">
                  <p class="title is-5 mb-1">Confidence-Aware Consistency Regularization (CCR)</p>
                  <p class="is-size-6 has-text-justified">
                    Uses a threshold-free dynamic weighting strategy. It adaptively shifts training focus from high-confidence known samples to low-confidence novel ones, effectively mitigating the impact of noisy pseudo-labels to ensure stable learning.
                  </p>
                </div>
              </div>
            </div>

            <div class="column is-12">
              <div class="media">
                <div class="media-left">
                  <span class="icon is-large has-text-success"><i class="fas fa-sliders-h fa-2x"></i></span>
                </div>
                <div class="media-content">
                  <p class="title is-5 mb-1">Asymmetric Confidence Reinforcement (ACR)</p>
                  <p class="is-size-6 has-text-justified">
                    Leverages dynamically adjusted asymmetric thresholds to independently select reliable pseudo-labels for known and novel classes, effectively bridging the confidence gap.
                  </p>
                </div>
              </div>
            </div>

            <div class="column is-12">
              <div class="media">
                <div class="media-left">
                  <span class="icon is-large has-text-warning"><i class="fas fa-cut fa-2x"></i></span>
                </div>
                <div class="media-content">
                  <p class="title is-5 mb-1">Dynamic Prototype Pruning (DPP)</p>
                  <p class="is-size-6 has-text-justified">
                    Estimates the number of novel forgery types without prior knowledge in a <b>coarse-to-fine</b> manner:
                  </p>
                  <div class="tags are-medium mt-2">
                    <span class="tag is-white">High-confidence Identification</span>
                    <span class="icon is-small"><i class="fas fa-arrow-right"></i></span>
                    <span class="tag is-white">Low-confidence Filtering</span>
                    <span class="icon is-small"><i class="fas fa-arrow-right"></i></span>
                    <span class="tag is-white">Similarity-driven Merge</span>
                  </div>
                </div>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section" id="experiments">
    <div class="container is-max-desktop">
      
      <h2 class="title is-3 has-text-centered mb-6">Experiments</h2>

      <div class="columns is-vcentered mb-6">
        <div class="column is-5">
          <div class="content has-text-justified">
            <h3 class="title is-4">1. The OWDFA-40 Benchmark</h3>
            <p>
              To simulate realistic open-world scenarios, we constructed the <b>OWDFA-40 Benchmark</b>, extending the original setup to include <b>40 advanced deepfake generation methods</b>.
            </p>
            <ul>
              <li>
                <b>Diversity:</b> Covers 5 categories including Face Swapping, Reenactment, Editing, Entire Face Synthesis, and <span style="color: #d9534f;">Diffusion-based Generation</span>.
              </li>
              <li>
                <b>Protocols:</b> We designed three protocols with varying degrees of "openness" to rigorously evaluate robustness against unseen paradigms.
              </li>
            </ul>
          </div>
        </div>

        <div class="column is-7">
          <figure class="image">
            <img src="static/images/datasets.png" alt="Overview of Deepfake Methods in OWDFA-40" style="border-radius: 5px; box-shadow: 0 0 10px rgba(0,0,0,0.1);">
            <figcaption class="has-text-centered is-size-7 mt-2">
              Table 1. Overview of Deepfake Methods and Protocol Splits.
            </figcaption>
          </figure>
        </div>
      </div>

      <hr class="divider">

      <div class="content has-text-justified">
        <h3 class="title is-4">2. Comparison with State-of-the-Art</h3>
        <p>
          We compare CAL with SOTA methods (CPL, CDAL) and strong baselines from GCD and OWSSL settings.
        </p>
        <div class="box" style="background-color: #f5f5f5;">
          <p class="is-size-6">
            <span class="icon has-text-success"><i class="fas fa-check-circle"></i></span> 
            <b>Key Finding:</b> CAL achieves a new state-of-the-art performance across all three protocols. Notably, it surpasses CPL by an average of <b>7.3% in Novel ACC</b>, demonstrating superior ability to discover unknown forgery types.
            <br>
            <span class="icon has-text-success"><i class="fas fa-check-circle"></i></span> 
            <b>Unknown K:</b> Even without knowing the number of novel types (<i>w/o K<sub>U</sub></i>), our method outperforms baselines that rely on this prior knowledge.
          </p>
        </div>

        <figure class="image mt-4 mb-6">
          <img src="static/images/results_sota.png" alt="SOTA Comparison Results" style="border-radius: 5px;">
          <figcaption class="has-text-centered is-size-7 mt-2">
            Table 2. Quantitative results on the OW-DFA-40 benchmark. Best results are bolded.
          </figcaption>
        </figure>
      </div>

      <hr class="divider">

      <div class="columns is-variable is-8">
        
        <div class="column is-6">
          <div class="content has-text-justified">
            <h3 class="title is-5 has-text-centered-mobile">3. Ablation Study</h3>
            <p class="is-size-6 mb-3">
              We conduct a step-by-step ablation to validate the effectiveness of our key components:
            </p>
            <ul class="is-size-6 mt-0" style="margin-left: 1.5em;">
              <li><b>Base Loss:</b> Foundational performance.</li>
              <li><b>CCR:</b> Boosts Novel ACC (+32.8%) by mitigating noise.</li>
              <li><b>ACR:</b> Bridges the confidence gap.</li>
              <li><b>FFE:</b> Improves generalized representation.</li>
            </ul>
            
            <figure class="image mt-5">
              <img src="static/images/results_ablation.png" alt="Ablation Study Table" style="border: 1px solid #eee; border-radius: 6px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
              <figcaption class="has-text-centered is-size-7 mt-2 has-text-grey">
                Table 3. Effectiveness of Key Components.
              </figcaption>
            </figure>
          </div>
        </div>

        <div class="column is-6">
          <div class="content has-text-justified">
            <h3 class="title is-5 has-text-centered-mobile">4. Estimating Unknown <i>K</i></h3>
            <p class="is-size-6 mb-4">
              Unlike GCD methods that rely on clustering accuracy of known classes to guess <i>K</i>, our <b>Dynamic Prototype Pruning (DPP)</b> strategy directly estimates the number of novel forgeries with much lower error.
            </p>
            
            <div class="is-hidden-mobile" style="height: 1.2rem;"></div>

            <figure class="image mt-4">
              <img src="static/images/results_k_estimation.png" alt="Class Number Estimation Results" style="border: 1px solid #eee; border-radius: 6px; box-shadow: 0 2px 5px rgba(0,0,0,0.05);">
              <figcaption class="has-text-centered is-size-7 mt-2 has-text-grey">
                Table 4. Estimation Error Comparison.
              </figcaption>
            </figure>
          </div>
        </div>

      </div>

    </div>
  </section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Poster Presentation</h2>
        <div class="publication-poster">
          <img src="static/images/poster.png" alt="Project Poster" style="width: 100%; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.1);">
        </div>
      </div>
    </div>
  </div>
</section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{zheng2025open,
  title={Open-World Deepfake Attribution via Confidence-Aware Asymmetric Learning},
  author={Zheng, Haiyang and Pu, Nan and Li, Wenjing and Long, Teng and Sebe, Nicu and Zhong, Zhun},
  journal={arXiv preprint arXiv:2512.12667},
  year={2025}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content has-text-centered">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> adopted from <a href="https://nerfies.github.io" target="_blank">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  </main>
</body>
</html>